{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjIPsYfmeZ60",
        "outputId": "4f77958b-9333-4573-8deb-a57a25337830"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEhXhiX0eQ2O"
      },
      "source": [
        "# **Generating Quotes using LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14ZMYLjZeQ2S"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "import keras.utils as ku\n",
        "from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "id": "d5xoTNweeQ2T",
        "outputId": "452b3e59-72a3-4e10-e676-970b10f721ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3001, 5)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6c864523-b82a-4cca-bd97-2361051b4a7c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>quote</th>\n",
              "      <th>author</th>\n",
              "      <th>tags</th>\n",
              "      <th>likes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Be yourself; everyone else is already taken.</td>\n",
              "      <td>Oscar Wilde</td>\n",
              "      <td>attributed-no-source;be-yourself;honesty;inspi...</td>\n",
              "      <td>149270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>You've gotta dance like there's nobody watching</td>\n",
              "      <td>William W. Purkey</td>\n",
              "      <td>dance;heaven;hurt;inspirational;life;love;sing</td>\n",
              "      <td>118888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Be the change that you wish to see in the world.</td>\n",
              "      <td>Mahatma Gandhi</td>\n",
              "      <td>action;change;inspirational;philosophy;wish</td>\n",
              "      <td>106749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>No one can make you feel inferior without your...</td>\n",
              "      <td>Eleanor Roosevelt,</td>\n",
              "      <td>confidence;inspirational;wisdom</td>\n",
              "      <td>85854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Live as if you were to die tomorrow. Learn as ...</td>\n",
              "      <td>Mahatma Gandhi</td>\n",
              "      <td>carpe-diem;education;inspirational;learning</td>\n",
              "      <td>73033</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c864523-b82a-4cca-bd97-2361051b4a7c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6c864523-b82a-4cca-bd97-2361051b4a7c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6c864523-b82a-4cca-bd97-2361051b4a7c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-17035590-2652-4df2-9889-0482b91a1288\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-17035590-2652-4df2-9889-0482b91a1288')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-17035590-2652-4df2-9889-0482b91a1288 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   index                                              quote  \\\n",
              "0      0       Be yourself; everyone else is already taken.   \n",
              "1      1    You've gotta dance like there's nobody watching   \n",
              "2      2   Be the change that you wish to see in the world.   \n",
              "3      3  No one can make you feel inferior without your...   \n",
              "4      4  Live as if you were to die tomorrow. Learn as ...   \n",
              "\n",
              "               author                                               tags  \\\n",
              "0         Oscar Wilde  attributed-no-source;be-yourself;honesty;inspi...   \n",
              "1   William W. Purkey     dance;heaven;hurt;inspirational;life;love;sing   \n",
              "2      Mahatma Gandhi        action;change;inspirational;philosophy;wish   \n",
              "3  Eleanor Roosevelt,                    confidence;inspirational;wisdom   \n",
              "4      Mahatma Gandhi        carpe-diem;education;inspirational;learning   \n",
              "\n",
              "    likes  \n",
              "0  149270  \n",
              "1  118888  \n",
              "2  106749  \n",
              "3   85854  \n",
              "4   73033  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Loading the dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/NLP PROJECT/eng/eng_quotes.csv')\n",
        "print(data.shape)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Hq8dF3ieQ2U"
      },
      "outputs": [],
      "source": [
        "quotes = []\n",
        "for i in data['quote']:\n",
        "    quotes.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6SeDv5neQ2V",
        "outputId": "43c454e4-9358-4cf8-b756-ed7f440ee561"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total unique words in the text corpus: 1362\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[12, 67],\n",
              " [12, 67, 153],\n",
              " [12, 67, 153, 216],\n",
              " [12, 67, 153, 216, 4],\n",
              " [12, 67, 153, 216, 4, 381]]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tokeinization\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Function to create the sequences\n",
        "def generate_sequences(corpus):\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    total_words = len(tokenizer.word_index) + 1\n",
        "    print(f\"Total unique words in the text corpus: {total_words}\")\n",
        "    input_sequences = []\n",
        "    for line in corpus:\n",
        "        seq = tokenizer.texts_to_sequences([line])[0]\n",
        "        for i in range(1, len(seq)):\n",
        "            ngram_seq = seq[:i+1]\n",
        "            input_sequences.append(ngram_seq)\n",
        "\n",
        "    return input_sequences, total_words\n",
        "\n",
        "# Generating sequences\n",
        "input_sequences, total_words = generate_sequences(quotes)\n",
        "input_sequences[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74DGwxDfeQ2V"
      },
      "source": [
        "Now that we have the data in required format, but each sequences are of different length. So, before feeding into the model, we will first pad the sequences to same length.\n",
        "\n",
        "Also, we need to create predictor and label from the prepared sequences by taking all the tokens except the last one as predictors and the last token as label (For example, think of it like the data in the above table: \"Don't cry\" as predictors and \"because\" as label)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WN1k8TeMeQ2W",
        "outputId": "79fe654b-c28a-4b52-f0a1-13d3742493cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  0,  0, 12]]),\n",
              " array([[0., 0., 0., ..., 0., 0., 0.]], dtype=float32))"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Generating predictors and labels from the padded sequences\n",
        "def generate_input_sequence(input_sequences):\n",
        "    maxlen = max([len(x) for x in input_sequences])\n",
        "    input_sequences = pad_sequences(input_sequences, maxlen=maxlen)\n",
        "    predictors, label = input_sequences[:, :-1], input_sequences[:, -1]\n",
        "    label = ku.to_categorical(label, num_classes=total_words)\n",
        "    return predictors, label, maxlen\n",
        "\n",
        "predictors, label, maxlen = generate_input_sequence(input_sequences)\n",
        "predictors[:1], label[:1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxgfjWRweQ2W"
      },
      "source": [
        "Finally, we are done with the preprocessing part of task. Now, we will start building our LSTM model for text generation. You can think of this model as a multiclass text classification task- given the previous words, the model will predict the next word which has high probability.\n",
        "\n",
        "**Model Architecture:**\n",
        "* Embedding layer with the embedding dimension of 64\n",
        "* LSTM Layer with 128 units with dropout\n",
        "* A dense layer with number of units equal to the total words in the vocabulary with **softmax** activation since it is a mulitclass classification task.\n",
        "* The optimizer we use here is **Adam**, loss is **categorical_crossentropy**, and an epoch of 50."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kaaxrwd7eQ2W",
        "outputId": "8f83522b-fdaa-4391-cf61-327ceaf7a8b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "198"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "maxlen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHxZvmBXeQ2W",
        "outputId": "2c096678-7665-455a-daf5-ba547d0ff402"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 197, 64)           87168     \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 128)               98816     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1362)              175698    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 361,682\n",
            "Trainable params: 361,682\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Building the model\n",
        "embedding_dim = 64\n",
        "\n",
        "def create_model(maxlen, embedding_dim, total_words):\n",
        "    model = Sequential()\n",
        "    model.add(layers.Embedding(total_words, embedding_dim, input_length = maxlen))\n",
        "    model.add(layers.LSTM(128, dropout=0.2))\n",
        "    model.add(layers.Dense(total_words, activation='softmax'))\n",
        "\n",
        "    # compiling the model\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "    return model\n",
        "\n",
        "model = create_model(maxlen-1, embedding_dim, total_words)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shYhN6THeQ2X",
        "outputId": "52e31098-3032-4d39-81ca-304889b10629"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((6034, 197), (6034, 1362), 198)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictors.shape , label.shape, maxlen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1HyuXrpeQ2X",
        "outputId": "e917732f-ae30-4fe8-e2bd-d301b28e4d5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "95/95 [==============================] - 21s 191ms/step - loss: 6.4016\n",
            "Epoch 2/50\n",
            "95/95 [==============================] - 19s 195ms/step - loss: 5.9436\n",
            "Epoch 3/50\n",
            "95/95 [==============================] - 18s 194ms/step - loss: 5.8450\n",
            "Epoch 4/50\n",
            "95/95 [==============================] - 18s 190ms/step - loss: 5.7801\n",
            "Epoch 5/50\n",
            "95/95 [==============================] - 18s 191ms/step - loss: 5.7284\n",
            "Epoch 6/50\n",
            "95/95 [==============================] - 17s 183ms/step - loss: 5.6665\n",
            "Epoch 7/50\n",
            "95/95 [==============================] - 17s 184ms/step - loss: 5.6039\n",
            "Epoch 8/50\n",
            "95/95 [==============================] - 19s 199ms/step - loss: 5.5396\n",
            "Epoch 9/50\n",
            "95/95 [==============================] - 19s 200ms/step - loss: 5.4678\n",
            "Epoch 10/50\n",
            "95/95 [==============================] - 19s 203ms/step - loss: 5.3872\n",
            "Epoch 11/50\n",
            "95/95 [==============================] - 18s 186ms/step - loss: 5.2961\n",
            "Epoch 12/50\n",
            "95/95 [==============================] - 20s 215ms/step - loss: 5.1976\n",
            "Epoch 13/50\n",
            "95/95 [==============================] - 19s 199ms/step - loss: 5.1005\n",
            "Epoch 14/50\n",
            "95/95 [==============================] - 19s 197ms/step - loss: 4.9982\n",
            "Epoch 15/50\n",
            "95/95 [==============================] - 18s 195ms/step - loss: 4.8956\n",
            "Epoch 16/50\n",
            "95/95 [==============================] - 17s 180ms/step - loss: 4.8018\n",
            "Epoch 17/50\n",
            "95/95 [==============================] - 20s 210ms/step - loss: 4.7069\n",
            "Epoch 18/50\n",
            "95/95 [==============================] - 19s 201ms/step - loss: 4.6170\n",
            "Epoch 19/50\n",
            "95/95 [==============================] - 20s 210ms/step - loss: 4.5227\n",
            "Epoch 20/50\n",
            "95/95 [==============================] - 21s 219ms/step - loss: 4.4387\n",
            "Epoch 21/50\n",
            "95/95 [==============================] - 18s 194ms/step - loss: 4.3474\n",
            "Epoch 22/50\n",
            "95/95 [==============================] - 18s 185ms/step - loss: 4.2642\n",
            "Epoch 23/50\n",
            "95/95 [==============================] - 17s 182ms/step - loss: 4.1762\n",
            "Epoch 24/50\n",
            "95/95 [==============================] - 17s 182ms/step - loss: 4.0920\n",
            "Epoch 25/50\n",
            "95/95 [==============================] - 18s 185ms/step - loss: 4.0084\n",
            "Epoch 26/50\n",
            "95/95 [==============================] - 18s 189ms/step - loss: 3.9264\n",
            "Epoch 27/50\n",
            "95/95 [==============================] - 18s 186ms/step - loss: 3.8432\n",
            "Epoch 28/50\n",
            "95/95 [==============================] - 18s 185ms/step - loss: 3.7559\n",
            "Epoch 29/50\n",
            "95/95 [==============================] - 18s 186ms/step - loss: 3.6709\n",
            "Epoch 30/50\n",
            "95/95 [==============================] - 18s 187ms/step - loss: 3.5973\n",
            "Epoch 31/50\n",
            "95/95 [==============================] - 18s 186ms/step - loss: 3.5088\n",
            "Epoch 32/50\n",
            "95/95 [==============================] - 18s 186ms/step - loss: 3.4287\n",
            "Epoch 33/50\n",
            "95/95 [==============================] - 18s 186ms/step - loss: 3.3555\n",
            "Epoch 34/50\n",
            "95/95 [==============================] - 18s 186ms/step - loss: 3.2790\n",
            "Epoch 35/50\n",
            "95/95 [==============================] - 21s 224ms/step - loss: 3.2004\n",
            "Epoch 36/50\n",
            "95/95 [==============================] - 19s 202ms/step - loss: 3.1285\n",
            "Epoch 37/50\n",
            "95/95 [==============================] - 19s 200ms/step - loss: 3.0507\n",
            "Epoch 38/50\n",
            "95/95 [==============================] - 19s 201ms/step - loss: 2.9824\n",
            "Epoch 39/50\n",
            "95/95 [==============================] - 19s 200ms/step - loss: 2.9092\n",
            "Epoch 40/50\n",
            "95/95 [==============================] - 19s 199ms/step - loss: 2.8406\n",
            "Epoch 41/50\n",
            "95/95 [==============================] - 20s 206ms/step - loss: 2.7774\n",
            "Epoch 42/50\n",
            "95/95 [==============================] - 20s 211ms/step - loss: 2.7069\n",
            "Epoch 43/50\n",
            "95/95 [==============================] - 20s 210ms/step - loss: 2.6483\n",
            "Epoch 44/50\n",
            "95/95 [==============================] - 19s 195ms/step - loss: 2.5851\n",
            "Epoch 45/50\n",
            "95/95 [==============================] - 21s 223ms/step - loss: 2.5256\n",
            "Epoch 46/50\n",
            "95/95 [==============================] - 20s 210ms/step - loss: 2.4588\n",
            "Epoch 47/50\n",
            "95/95 [==============================] - 20s 205ms/step - loss: 2.4098\n",
            "Epoch 48/50\n",
            "95/95 [==============================] - 18s 188ms/step - loss: 2.3510\n",
            "Epoch 49/50\n",
            "95/95 [==============================] - 18s 188ms/step - loss: 2.3051\n",
            "Epoch 50/50\n",
            "95/95 [==============================] - 20s 209ms/step - loss: 2.2529\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1b5baaccd10>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Training the model\n",
        "model.fit(predictors, label, epochs=50, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Vuo77AxeQ2X"
      },
      "source": [
        "The model has been trained for almost two hours for only 50 epochs. So, will save the model to avoid training every time we want to generate a pice of text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvBra5p7eQ2X"
      },
      "outputs": [],
      "source": [
        "# Save the model for later use\n",
        "# model.save(\"Quotes_generator.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUeuyzZaeQ2Y"
      },
      "outputs": [],
      "source": [
        "# Loading the model\n",
        "from keras.models import load_model\n",
        "\n",
        "Quotes_gen = load_model(\"../input/quote-generator-trained-model/Quotes_generator.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tj_pEHXzeQ2Y",
        "outputId": "1acbcbcf-690f-45e9-b13d-572869d0a145"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 82, 64)            629504    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 9836)              1268844   \n",
            "=================================================================\n",
            "Total params: 1,997,164\n",
            "Trainable params: 1,997,164\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "Quotes_gen.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esS4rd9YeQ2Y"
      },
      "source": [
        "Now that we have our trained model, we will create a function to generate text.\n",
        "\n",
        "The function takes in the trained model, the input words (also called seed text), how many words to genereate and maximum squence length. The function then tokenize the text, padds it and predict using our trained model.\n",
        "\n",
        "The model predicts one word at a time. So after every prediction, we will get the word for the predicted label and append it to the seed_text. This process continues for the specified number of words you want to genereate. And once it is done, the text will then be returned.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFzuCqqieQ2Y"
      },
      "outputs": [],
      "source": [
        "# Text generating function\n",
        "def generate_quote(seed_text, num_words, model, maxlen):\n",
        "\n",
        "    for _ in range(num_words):\n",
        "        tokens = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        tokens = pad_sequences([tokens], maxlen=maxlen, padding='pre')\n",
        "\n",
        "        predicted = np.argmax(model.predict(tokens))\n",
        "\n",
        "        output_word = ''\n",
        "\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text = \"\\n\" + seed_text + \" \" + output_word\n",
        "\n",
        "    return seed_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtoUP3DteQ2Y",
        "outputId": "d295e0f0-f2f4-43fa-de99-de07d393417e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Passion women seldom make a heart should be so hidden in\n"
          ]
        }
      ],
      "source": [
        "# Let's try to generate some quotes\n",
        "print(generate_quote(\"Passion\", num_words = 10, model= model, maxlen=maxlen-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoaJcem-eQ2Y",
        "outputId": "d38795a0-aea1-42e8-9194-523d78092475"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "legend he be a response it's finest books you love a good work of live and\n"
          ]
        }
      ],
      "source": [
        "print(generate_quote(\"legend\", num_words = 15, model= Quotes_gen, maxlen=maxlen))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2vvMfZEeQ2Y",
        "outputId": "63d47742-041d-4200-939d-9c6815135df9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "consistency matters not the some of self world's jump know in one not the seeing of the\n"
          ]
        }
      ],
      "source": [
        "print(generate_quote(\"consistency matters\", num_words = 15, model= Quotes_gen, maxlen=maxlen))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
